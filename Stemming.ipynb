{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHHGj0FU9gUFhTbl8xIWfD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasrieka/Cyber-Security_Caesar-Chiper/blob/master/Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cYLjsisnWlJ",
        "outputId": "fa6c4b24-a531-40f3-9500-20d1b16b4351"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umJ_GkVJqdRu"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcaZoB9YrSsw",
        "outputId": "6e0c4f2d-3c81-4862-e123-1c4ce94e6156"
      },
      "source": [
        "!pip install Sastrawi\n",
        "!pip install plotly\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from collections import Counter\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "#import os\n",
        "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    #for filename in filenames:\n",
        "        #print(os.path.join(dirname, filename))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSRoIe30qnF5"
      },
      "source": [
        "def stem_lem_text(s, type='Lancaster'):\n",
        "    words = s.split()\n",
        "    \n",
        "    if type == 'Porter':\n",
        "        choice = PorterStemmer()\n",
        "        reformed = [choice.stem(word) for word in words]\n",
        "    elif type == 'Snowball':\n",
        "        choice = SnowballStemmer('english')\n",
        "        reformed = [choice.stem(word) for word in words]\n",
        "    elif type == 'Lemmatize':\n",
        "        choice = WordNetLemmatizer()\n",
        "        reformed = [choice.lemmatize(word) for word in words]\n",
        "    else:\n",
        "        choice = LancasterStemmer()\n",
        "        reformed = [choice.stem(word) for word in words]\n",
        "        \n",
        "    reformed = \" \".join(reformed)\n",
        "    return reformed"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QykJfV29qvTS"
      },
      "source": [
        "import tensorflow as tf\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Big Data Eka/Salinan Train1.csv\", usecols=[\"label\", \"reviewText\", \"selected_text\" ])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2rr_--TrCOY",
        "outputId": "56e11c73-e3d4-4158-afc4-53dbe9f1b2b7"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400001 entries, 0 to 400000\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   label          400001 non-null  int64 \n",
            " 1   reviewText     400001 non-null  object\n",
            " 2   selected_text  399998 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 9.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "0YNHqiJKsb0J",
        "outputId": "baaf4b48-abd8-4f08-8a0f-63a9f038dd41"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>356625</th>\n",
              "      <td>1</td>\n",
              "      <td>The Pros: Great looking, small and compact, ea...</td>\n",
              "      <td>pros great looking small compact easy use radi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209430</th>\n",
              "      <td>1</td>\n",
              "      <td>I really liked this group, when they were Stai...</td>\n",
              "      <td>really liked group stained cd sounds exactly l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354857</th>\n",
              "      <td>2</td>\n",
              "      <td>This was Godsend for me postpartum. I tried so...</td>\n",
              "      <td>godsend postpartum tried many different things...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291676</th>\n",
              "      <td>1</td>\n",
              "      <td>I run 3-4 times per week. These headphones are...</td>\n",
              "      <td>run times per week headphones good light worko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276549</th>\n",
              "      <td>1</td>\n",
              "      <td>I bought 2: 1 of them came broken. The other o...</td>\n",
              "      <td>bought came broken one broke third day poorest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2847</th>\n",
              "      <td>1</td>\n",
              "      <td>the movie was bad the kid ruined it yellign an...</td>\n",
              "      <td>movie bad kid ruined yellign angry whole time ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352808</th>\n",
              "      <td>2</td>\n",
              "      <td>There isn't much that I can say about this mov...</td>\n",
              "      <td>isnt much say movie hasnt said critics reviewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311625</th>\n",
              "      <td>1</td>\n",
              "      <td>I just returned my Garmin nuvi 200 after tryin...</td>\n",
              "      <td>returned garmin nuvi trying drive bronx manhat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104432</th>\n",
              "      <td>2</td>\n",
              "      <td>I bought the game used expecting it to be scra...</td>\n",
              "      <td>bought game used expecting scratched way would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48070</th>\n",
              "      <td>2</td>\n",
              "      <td>My grandson has been enthralled with this sinc...</td>\n",
              "      <td>grandson enthralled since newborn would start ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        label  ...                                      selected_text\n",
              "356625      1  ...  pros great looking small compact easy use radi...\n",
              "209430      1  ...  really liked group stained cd sounds exactly l...\n",
              "354857      2  ...  godsend postpartum tried many different things...\n",
              "291676      1  ...  run times per week headphones good light worko...\n",
              "276549      1  ...  bought came broken one broke third day poorest...\n",
              "2847        1  ...  movie bad kid ruined yellign angry whole time ...\n",
              "352808      2  ...  isnt much say movie hasnt said critics reviewe...\n",
              "311625      1  ...  returned garmin nuvi trying drive bronx manhat...\n",
              "104432      2  ...  bought game used expecting scratched way would...\n",
              "48070       2  ...  grandson enthralled since newborn would start ...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYzered1ueG6"
      },
      "source": [
        "df = df[df['selected_text'].notnull()]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCYR7qVZs-k4",
        "outputId": "7a9e5491-2f37-481a-f771-14f2967da584"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNTmkEvSsewP",
        "outputId": "3c877e72-fc26-40f3-c19e-ada073648670"
      },
      "source": [
        "print('Step1')\n",
        "df['text_porter'] = df['selected_text'].apply(stem_lem_text, type='Porter')\n",
        "df['text_snowball'] = df['selected_text'].apply(stem_lem_text, type='Snowball')\n",
        "df['text_lemmatize'] = df['selected_text'].apply(stem_lem_text, type='Lemmatize')\n",
        "print('Done')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step1\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptnot1h4sjEw"
      },
      "source": [
        "df.to_csv('/content/drive/MyDrive/Big Data Eka/Train1_stemmed_lemmatized_no_extra_stops.csv', index=None, encoding='utf-8')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4_u0cgvxjsL"
      },
      "source": [
        "import tensorflow as tf\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Big Data Eka/Train1_stemmed_lemmatized_no_extra_stops.csv\", usecols=[\"label\", \"reviewText\", \"selected_text\" ])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "-T3jBVdFxxVL",
        "outputId": "c404b288-0fb0-4a0f-8f89-fd48cd13471a"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210928</th>\n",
              "      <td>1</td>\n",
              "      <td>The reason the call this book \"for dummies\" is...</td>\n",
              "      <td>reason call book dummies moron buy teaches eno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266610</th>\n",
              "      <td>2</td>\n",
              "      <td>when I was 15 (which is actually a long time a...</td>\n",
              "      <td>actually long time ago band favorite since hel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360059</th>\n",
              "      <td>2</td>\n",
              "      <td>This book is a compilation of about two dozen ...</td>\n",
              "      <td>book compilation two dozen interviews conducte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299441</th>\n",
              "      <td>1</td>\n",
              "      <td>My problem is that I'm a completist. This mean...</td>\n",
              "      <td>problem im completist means consider something...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260853</th>\n",
              "      <td>1</td>\n",
              "      <td>I bought these because Baby Bargains' book sta...</td>\n",
              "      <td>bought baby bargains book stated bottles top l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145073</th>\n",
              "      <td>2</td>\n",
              "      <td>It seems at first that Dennis Bennett simply s...</td>\n",
              "      <td>seems first dennis bennett simply stumbled ont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35509</th>\n",
              "      <td>1</td>\n",
              "      <td>Anyone interested in purchasing this import si...</td>\n",
              "      <td>anyone interested purchasing import single imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215808</th>\n",
              "      <td>1</td>\n",
              "      <td>This book, like most written and portraying Hu...</td>\n",
              "      <td>book like written portraying hurricane katrina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343849</th>\n",
              "      <td>2</td>\n",
              "      <td>Ice Cube is the embodiment of Gansterism. He's...</td>\n",
              "      <td>ice cube embodiment gansterism hes og shows pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81853</th>\n",
              "      <td>1</td>\n",
              "      <td>i had this for 2 years and used it about once ...</td>\n",
              "      <td>years used month happy first since easy use ho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        label  ...                                      selected_text\n",
              "210928      1  ...  reason call book dummies moron buy teaches eno...\n",
              "266610      2  ...  actually long time ago band favorite since hel...\n",
              "360059      2  ...  book compilation two dozen interviews conducte...\n",
              "299441      1  ...  problem im completist means consider something...\n",
              "260853      1  ...  bought baby bargains book stated bottles top l...\n",
              "145073      2  ...  seems first dennis bennett simply stumbled ont...\n",
              "35509       1  ...  anyone interested purchasing import single imp...\n",
              "215808      1  ...  book like written portraying hurricane katrina...\n",
              "343849      2  ...  ice cube embodiment gansterism hes og shows pl...\n",
              "81853       1  ...  years used month happy first since easy use ho...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVv5WYukx1G7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}